import os
import json
from datetime import datetime
import streamlit as st
from llama_index.core import load_index_from_storage
from llama_index.core import StorageContext
from llama_index.core.memory import ChatMemoryBuffer
from llama_index.core.tools import QueryEngineTool, ToolMetadata
from llama_index.agent.openai import OpenAIAgent
from llama_index.core.storage.chat_store import SimpleChatStore
from llama_index.core.tools import FunctionTool
from src.global_settings import INDEX_STORAGE, CONVERSATION_FILE, SCORES_FILE
from src.prompts import CUSTOM_AGENT_SYSTEM

user_avatar = "data/images/user.png"
professor_avatar = "data/images/ai_icon.png"

def load_chat_store():
    """T·∫£i l·ªãch s·ª≠ chat t·ª´ file n·∫øu c√≥, n·∫øu kh√¥ng kh·ªüi t·∫°o m·ªõi."""
    if os.path.exists(CONVERSATION_FILE) and os.path.getsize(CONVERSATION_FILE) > 0:
        try:
            chat_store = SimpleChatStore.from_persist_path(CONVERSATION_FILE)
        except json.JSONDecodeError:
            chat_store = SimpleChatStore()
    else:
        chat_store = SimpleChatStore()
    return chat_store

def display_messages(chat_store, container, key):
    """Hi·ªÉn th·ªã tin nh·∫Øn t·ª´ l·ªãch s·ª≠ chat."""
    with container:
        for message in chat_store.get_messages(key=key):
            if message.role == "user":
                with st.chat_message(message.role, avatar=user_avatar):
                    st.markdown(message.content)
            elif message.role == "assistant" and message.content != None:
                with st.chat_message(message.role, avatar=professor_avatar):
                    st.markdown(message.content)
def save_score(score, content, total_guess, username):
        """Ghi ƒëi·ªÉm v√† n·ªôi dung ƒë√°nh gi√° v√†o file

        Args:
            score (string): ƒêi·ªÉm s·ªë ƒë√°nh gi√° s·ª©c kh·ªèe t√¢m l√Ω c·ªßa user
            content (string): N·ªôi dung chi ti·∫øt li√™n quan ƒë·∫øn k·∫øt qu·∫£ ƒë√°nh gi√° ho·∫∑c ph·∫£n h·ªìi c·ª• th·ªÉ c·ªßa chatbot v·ªõi user
            total_guess (string):T·ªïng s·ªë l·∫ßn ph√¢n t√≠ch s·ª©c kh·ªèe t√¢m l√Ω c·ªßa user
        """
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        new_entry = {
            "username": username,
            "Time": current_time,
            "Score": score,
            "Content": content,
            "Total guess": total_guess
        }

        # ƒê·ªçc d·ªØ li·ªáu t·ª´ file n·∫øu t·ªìn t·∫°i
        try:
            with open(SCORES_FILE, "r") as f:
                data = json.load(f)
        except FileNotFoundError:
            data = []

        # Th√™m d·ªØ li·ªáu m·ªõi v√†o danh s√°ch
        data.append(new_entry)

        # Ghi d·ªØ li·ªáu tr·ªü l·∫°i file
        with open(SCORES_FILE, "w") as f:
            json.dump(data, f, indent=4)

def initialize_chatbot(chat_store, container, username, user_info):
    memory = ChatMemoryBuffer.from_defaults(
        token_limit=3000,
        chat_store=chat_store,
        chat_store_key=username
    )
    storage_context = StorageContext.from_defaults(
        persist_dir=INDEX_STORAGE
    )
    index = load_index_from_storage(
        storage_context, index_id="vector"
    )
    dsm5_engine = index.as_query_engine(
        similarity_top_k=3,
    )
    dsm5_tool= QueryEngineTool(
        query_engine=dsm5_engine,
        metadata=ToolMetadata(
            name="dsm5",
            description=(
                f"Cung c·∫•p c√°c th√¥ng tin li√™n quan ƒë·∫øn c√°c b·ªánh "
                f"t√¢m th·∫ßn theo ti√™u chu·∫©n DSM5. S·ª≠ d·ª•ng c√¢u h·ªèi vƒÉn b·∫£n thu·∫ßn t√∫y chi ti·∫øt l√†m ƒë·∫ßu v√†o cho c√¥ng c·ª•"
            ),
        )
    )
    save_tool = FunctionTool.from_defaults(fn=save_score)
    agent = OpenAIAgent.from_tools(
        tools=[dsm5_tool, save_tool],
        memory=memory,
        system_prompt=CUSTOM_AGENT_SYSTEM.format(user_info=user_info)
    )
    display_messages(chat_store, container, key=username)
    return agent

def chat_interface(agent, chat_store, container):
    with container:
        with st.chat_message(name="assistant", avatar=professor_avatar):
            st.markdown("Ch√†o b·∫°n, m√¨nh l√† MENTAL CARE. M√¨nh lu√¥n ·ªü ƒë√¢y ƒë·ªÉ ƒë·ªÉ l·∫Øng nghe, chia s·∫ª v√† ƒë·ªìng h√†nh c√πng b·∫°n üéà")
    prompt = st.chat_input("H√£y chia s·∫ª v·∫•n ƒë·ªÅ c·ªßa b·∫°n t·∫°i ƒë√¢y ...")
    if prompt:
        with container:
            with st.chat_message(name="user", avatar=user_avatar):
                st.markdown(prompt)
            response = str(agent.chat(prompt))
            with st.chat_message(name="assistant", avatar=professor_avatar):
                st.markdown(response)
            """assistant_message = st.chat_message(name="assistant", avatar=professor_avatar)
            message_placeholder = assistant_message.empty()
            # S·ª≠ d·ª•ng stream_chat ƒë·ªÉ nh·∫≠n ph·∫£n h·ªìi t·ª´ng token m·ªôt
            response = agent.stream_chat(prompt)
            # T·∫°o m·ªôt bi·∫øn ƒë·ªÉ l∆∞u tr·ªØ n·ªôi dung ph·∫£n h·ªìi
            full_response = ""
            # L·∫∑p qua c√°c token v√† k·∫øt h·ª£p ch√∫ng th√†nh c√¢u ho√†n ch·ªânh
            for token in response.response_gen:
                full_response += token
                message_placeholder.markdown(full_response)"""
        chat_store.persist(CONVERSATION_FILE)
